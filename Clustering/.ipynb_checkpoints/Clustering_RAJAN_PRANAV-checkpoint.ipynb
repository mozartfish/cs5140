{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some stuff\n",
    "import numpy as np\n",
    "from math import inf \n",
    "import random \n",
    "import sys\n",
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and processing the data for running the different clustering algorithms\n",
    "\n",
    "# Helper Function that standardizes the c1 data for hierarchical clustering\n",
    "def standardize_c1_data():\n",
    "    # list that contains all the vector ids\n",
    "    id_list = []\n",
    "    # list that contains all the x coordinates of the vectors\n",
    "    x_coord_list = []\n",
    "    # list that contains all the y coordinates of the vectors\n",
    "    y_coord_list = []\n",
    "    # list that contains all the point xi in X in separate clusters Si\n",
    "    X = []\n",
    "    \n",
    "    # read in data\n",
    "    # with open does try, catch and close for files like scanners in java\n",
    "    with open('C1.txt', 'r') as data:\n",
    "        c1_data = data.readlines()\n",
    "    \n",
    "    # process the data, vectors are strings of characters separated by new lines and two tabs\n",
    "    for vector in c1_data:\n",
    "        # turn all the new line characters to empty spaces in the vector string\n",
    "        vector = vector.replace('\\n', '')\n",
    "        # turn the vector into a list containing an id and components\n",
    "        vector = vector.split('  ')\n",
    "        \n",
    "        # get components and convert them into proper types\n",
    "        vector_id = int(vector[0])\n",
    "        x_coord = float(vector[1])\n",
    "        y_coord = float(vector[2])\n",
    "        \n",
    "        # update the lists\n",
    "        id_list.append(vector_id)\n",
    "        x_coord_list.append(x_coord)\n",
    "        y_coord_list.append(y_coord)\n",
    "        \n",
    "    \n",
    "    for i in range(len(id_list)):\n",
    "        x_coord = x_coord_list[i]\n",
    "        y_coord = y_coord_list[i]\n",
    "        vector = (x_coord, y_coord)\n",
    "        cluster_Si = [vector]\n",
    "        X.append(cluster_Si)\n",
    "  \n",
    "    return X\n",
    "        \n",
    "    \n",
    "# Helper Function that standardizes the c2 data for assignment base clustering\n",
    "def standardize_c2_data():\n",
    "    # list that contains all the vector ids\n",
    "    id_list = []\n",
    "    # list that contains all the x coordinates of the vectors\n",
    "    x_coord_list = []\n",
    "    # list that contains all the y coordianates of the vectors\n",
    "    y_coord_list = []\n",
    "    # list that contains all the point xi in X in separate Clusters Si\n",
    "    X = []\n",
    "    \n",
    "    # read in data\n",
    "    with open('C2.txt', 'r') as data:\n",
    "        c2_data = data.readlines()\n",
    "    \n",
    "    # process the data, vectors are strings of characters separated by new lines and two tabs\n",
    "    for vector in c2_data:\n",
    "        # turn all the new line characters to empty spaces in the vector string\n",
    "        vector = vector.replace('\\n', '')\n",
    "        # turn the vector into a list containing an id and components\n",
    "        vector = vector.split('  ')\n",
    "        \n",
    "        # get components and convert them into proper types\n",
    "        vector_id = int(vector[0])\n",
    "        x_coord = float(vector[1])\n",
    "        y_coord = float(vector[2])\n",
    "        \n",
    "        # update the lists\n",
    "        id_list.append(vector_id)\n",
    "        x_coord_list.append(x_coord)\n",
    "        y_coord_list.append(y_coord)\n",
    "        \n",
    "    \n",
    "    for i in range(len(id_list)):\n",
    "        x_coord = x_coord_list[i]\n",
    "        y_coord = y_coord_list[i]\n",
    "        vector = (x_coord, y_coord)\n",
    "        cluster_Si = [vector]\n",
    "        X.append(cluster_Si)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Methods for hierarchical clustering\n",
    "\n",
    "# SINGLE-LINK METRIC\n",
    "# Function that defines the single-link metric\n",
    "# S1 represents a cluster S1, S2 represents a cluster S2\n",
    "def single_link(S1, S2):\n",
    "    # define the min distance to be some really large number \n",
    "    # so we can eventually get to a small number\n",
    "    min_distance = inf \n",
    "    for i in range(len(S1)):\n",
    "        for j in range(len(S2)):\n",
    "            # get current element of the first cluster\n",
    "            s1_element = list(S1[i])\n",
    "            s1_element = np.array(s1_element)\n",
    "#             print(f\"The S1 ELEMENT: {s1_element}\")\n",
    "            \n",
    "            # get current element of the second cluster\n",
    "            s2_element = list(S2[j])\n",
    "            s2_element = np.array(s2_element)\n",
    "#             print(f\"The S2 ELEMENT: {s2_element}\")\n",
    "            \n",
    "            # compute the distance between the two elements\n",
    "            dist = np.linalg.norm(s1_element - s2_element)\n",
    "            \n",
    "            # update the distance\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "    \n",
    "    return min_distance\n",
    "\n",
    "# COMPLETE-LINK METRIC\n",
    "# Function that defines the complete-link metric\n",
    "# Sl represents a cluster S1, S2 represets a cluster S2\n",
    "def complete_link(S1, S2):\n",
    "    # define the max distance to be some really large number\n",
    "    # so we can eventually get to a large number\n",
    "    max_distance = -inf\n",
    "    for g in range(len(S1)):\n",
    "        for h in range(len(S2)):\n",
    "            # get current element of the first cluster\n",
    "            s1_element = list(S1[g])\n",
    "            s1_element = np.array(s1_element)\n",
    "            \n",
    "            # get current element of the second cluster\n",
    "            s2_element = list(S2[h])\n",
    "            s2_element = np.array(s2_element)\n",
    "            \n",
    "            # compute the distance between the two elements\n",
    "            dist = np.linalg.norm(s1_element - s2_element)\n",
    "            \n",
    "            # update the distance\n",
    "            if dist > max_distance:\n",
    "                max_distance = dist\n",
    "    return max_distance\n",
    "            \n",
    "# MEAN-LINK METRIC\n",
    "# Function that defines the mean-link metric\n",
    "# S1 represents a cluster S1, S2 represents a cluster S2\n",
    "def mean_link(S1, S2):\n",
    "    # sum up all the points in cluster S1\n",
    "    cluster_s1_sum = np.zeros(2)\n",
    "    for w in range(len(S1)):\n",
    "        s1_element = list(S1[w])\n",
    "        s1_element = np.array(s1_element)\n",
    "        cluster_1_sum = np.add(cluster_s1_sum, s1_element)\n",
    "    \n",
    "    # sum up all the points in cluster S2\n",
    "    cluster_s2_sum = np.zeros(2)\n",
    "    for t in range(len(S2)):\n",
    "        s2_element = list(S2[t])\n",
    "        s2_element = np.array(s2_element)\n",
    "        cluster_2_sum = np.add(cluster_s2_sum, s2_element)\n",
    "#         cluster_s2_sum.add(s2_element)\n",
    "    \n",
    "    # Divide by the length of the clusters\n",
    "    cluster_1_sum = cluster_1_sum / len(S1)\n",
    "    cluster_2_sum = cluster_2_sum / len(S2)\n",
    "    \n",
    "    # compute the mean distance\n",
    "    mean_distance = np.linalg.norm(cluster_1_sum - cluster_2_sum)\n",
    "    \n",
    "    return mean_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-link clustering\n",
      "complete-link clustering\n",
      "mean-link clustering\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical Clustering (From Professor Jeff Phillips Data Mining Notes)\n",
    "\n",
    "# Function that performs Hierarchical Clustering with a specific linkage\n",
    "# First argument is the set of points X, Second Argument is the specific linkage\n",
    "def hierarchical_clustering(data, metric_type, metric_name):\n",
    "    if metric_name == \"single-link\":\n",
    "        print(\"single-link clustering\")\n",
    "        clustered_data = clustering(data, metric_type)\n",
    "        return clustered_data\n",
    "        \n",
    "    elif metric_name == \"complete-link\":\n",
    "        print(\"complete-link clustering\")\n",
    "        clustered_data = clustering(data, metric_type)\n",
    "        return clustered_data\n",
    "    else:\n",
    "        print(\"mean-link clustering\")\n",
    "        clustered_data = clustering(data, metric_type)\n",
    "        return clustered_data\n",
    "\n",
    "original_data = standardize_c1_data()\n",
    "# print(original_data)\n",
    "# for cluster in data:\n",
    "#     print(cluster)\n",
    "    \n",
    "single_link_clusters = hierarchical_clustering(original_data, single_link, \"single-link\")\n",
    "complete_link_clusters = hierarchical_clustering(original_data, complete_link, \"complete-link\")\n",
    "mean_link_clusters = hierarchical_clustering(original_data, mean_link, \"mean-link\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that performs single link clustering\n",
    "# data is an argument which contains the original number of clusters\n",
    "# metric_type is the kind of clustering we are using: Single-Link, Complete-Link, Mean-Link\n",
    "def clustering(clusters, metric):\n",
    "    # the data is 19 clusters the goal is to get it down to 4 clusters\n",
    "#     print(f\"The current number of clusters at the beginning: {len(clusters)}\")\n",
    "#     print()\n",
    "    \n",
    "    # variable that keeps track of the number of clusters we want\n",
    "    k = 4\n",
    "    # Stop computing clusters when the length of the cluster\n",
    "    while len(clusters) != k:\n",
    "        dist_s = [metric(c1, c2) for c1, c2 in combinations(clusters, 2)]\n",
    "        lowest_dist_index = np.argmin(dist_s)  \n",
    "        closest_clusters = list(combinations(clusters, 2))[lowest_dist_index]\n",
    "        closest_cluster_Si, closest_cluster_Sj = closest_clusters\n",
    "        clusters.remove(closest_cluster_Si)\n",
    "        clusters.remove(closest_cluster_Sj)\n",
    "        clusters.append(closest_cluster_Si + closest_cluster_Sj)\n",
    "#         print(f\"The new number of clusters is: {len(clusters)}\")\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment based clustering\n",
    "\n",
    "# load data\n",
    "original_data = standardize_c2_data()\n",
    "\n",
    "\n",
    "def gonzalez_algorithm(clusters):\n",
    "    # choose c1 in X arbitrarily. In this case we let C1 be first point\n",
    "    set_C = []\n",
    "    set_C.append(clusers[0])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
