{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some stuff\n",
    "import numpy as np\n",
    "import math\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and store documents\n",
    "def document_reader(file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    if (f.mode == \"r\"):\n",
    "        contents = f.read()\n",
    "        return contents\n",
    "\n",
    "doc_1 = document_reader(\"D1.txt\")\n",
    "doc_2 = document_reader(\"D2.txt\")\n",
    "doc_3 = document_reader(\"D3.txt\")\n",
    "doc_4 = document_reader(\"D4.txt\")\n",
    "\n",
    "# print statements for debugging the documents\n",
    "\n",
    "# print(doc_1)\n",
    "# print(doc_2)\n",
    "# print(doc_3)\n",
    "# print(doc_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2-gram based on characters\n",
      "The number of characters in the document: 1888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{' a',\n",
       " ' b',\n",
       " ' c',\n",
       " ' d',\n",
       " ' e',\n",
       " ' f',\n",
       " ' g',\n",
       " ' h',\n",
       " ' i',\n",
       " ' j',\n",
       " ' k',\n",
       " ' l',\n",
       " ' m',\n",
       " ' n',\n",
       " ' o',\n",
       " ' p',\n",
       " ' q',\n",
       " ' r',\n",
       " ' s',\n",
       " ' t',\n",
       " ' u',\n",
       " ' v',\n",
       " ' w',\n",
       " ' y',\n",
       " 'a ',\n",
       " 'ab',\n",
       " 'ac',\n",
       " 'ad',\n",
       " 'af',\n",
       " 'ag',\n",
       " 'ai',\n",
       " 'aj',\n",
       " 'ak',\n",
       " 'al',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ap',\n",
       " 'ar',\n",
       " 'as',\n",
       " 'at',\n",
       " 'au',\n",
       " 'av',\n",
       " 'aw',\n",
       " 'ay',\n",
       " 'ba',\n",
       " 'be',\n",
       " 'bi',\n",
       " 'bl',\n",
       " 'br',\n",
       " 'bu',\n",
       " 'by',\n",
       " 'c ',\n",
       " 'ca',\n",
       " 'ce',\n",
       " 'ch',\n",
       " 'ck',\n",
       " 'cl',\n",
       " 'co',\n",
       " 'cr',\n",
       " 'cs',\n",
       " 'ct',\n",
       " 'cu',\n",
       " 'd ',\n",
       " 'da',\n",
       " 'db',\n",
       " 'dd',\n",
       " 'de',\n",
       " 'dl',\n",
       " 'dn',\n",
       " 'do',\n",
       " 'dr',\n",
       " 'ds',\n",
       " 'du',\n",
       " 'dv',\n",
       " 'e ',\n",
       " 'ea',\n",
       " 'eb',\n",
       " 'ec',\n",
       " 'ed',\n",
       " 'ee',\n",
       " 'ei',\n",
       " 'el',\n",
       " 'em',\n",
       " 'en',\n",
       " 'eo',\n",
       " 'er',\n",
       " 'es',\n",
       " 'et',\n",
       " 'ev',\n",
       " 'ew',\n",
       " 'ex',\n",
       " 'f ',\n",
       " 'fa',\n",
       " 'fe',\n",
       " 'ff',\n",
       " 'fi',\n",
       " 'fl',\n",
       " 'fo',\n",
       " 'fr',\n",
       " 'ft',\n",
       " 'fu',\n",
       " 'g ',\n",
       " 'ga',\n",
       " 'ge',\n",
       " 'gg',\n",
       " 'gh',\n",
       " 'gi',\n",
       " 'gn',\n",
       " 'go',\n",
       " 'gr',\n",
       " 'gs',\n",
       " 'h ',\n",
       " 'ha',\n",
       " 'hd',\n",
       " 'he',\n",
       " 'hi',\n",
       " 'ho',\n",
       " 'ht',\n",
       " 'hy',\n",
       " 'i ',\n",
       " 'ic',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ig',\n",
       " 'ii',\n",
       " 'ik',\n",
       " 'il',\n",
       " 'im',\n",
       " 'in',\n",
       " 'io',\n",
       " 'ip',\n",
       " 'ir',\n",
       " 'is',\n",
       " 'it',\n",
       " 'iv',\n",
       " 'jo',\n",
       " 'ju',\n",
       " 'k ',\n",
       " 'ke',\n",
       " 'ki',\n",
       " 'ks',\n",
       " 'ky',\n",
       " 'l ',\n",
       " 'la',\n",
       " 'ld',\n",
       " 'le',\n",
       " 'lf',\n",
       " 'lg',\n",
       " 'li',\n",
       " 'll',\n",
       " 'lo',\n",
       " 'ls',\n",
       " 'lu',\n",
       " 'ly',\n",
       " 'm ',\n",
       " 'ma',\n",
       " 'md',\n",
       " 'me',\n",
       " 'mi',\n",
       " 'mo',\n",
       " 'mp',\n",
       " 'mx',\n",
       " 'n ',\n",
       " 'na',\n",
       " 'nc',\n",
       " 'nd',\n",
       " 'ne',\n",
       " 'ng',\n",
       " 'ni',\n",
       " 'no',\n",
       " 'ns',\n",
       " 'nt',\n",
       " 'ny',\n",
       " 'o ',\n",
       " 'ob',\n",
       " 'oc',\n",
       " 'od',\n",
       " 'of',\n",
       " 'og',\n",
       " 'ok',\n",
       " 'ol',\n",
       " 'om',\n",
       " 'on',\n",
       " 'oo',\n",
       " 'or',\n",
       " 'os',\n",
       " 'ot',\n",
       " 'ou',\n",
       " 'ow',\n",
       " 'p ',\n",
       " 'pa',\n",
       " 'pe',\n",
       " 'pi',\n",
       " 'pl',\n",
       " 'po',\n",
       " 'pr',\n",
       " 'pu',\n",
       " 'qu',\n",
       " 'r ',\n",
       " 'ra',\n",
       " 'rc',\n",
       " 'rd',\n",
       " 're',\n",
       " 'rf',\n",
       " 'rh',\n",
       " 'ri',\n",
       " 'rk',\n",
       " 'rl',\n",
       " 'rm',\n",
       " 'rn',\n",
       " 'ro',\n",
       " 'rp',\n",
       " 'rr',\n",
       " 'rs',\n",
       " 'rt',\n",
       " 'ru',\n",
       " 'ry',\n",
       " 's ',\n",
       " 'se',\n",
       " 'sh',\n",
       " 'si',\n",
       " 'sm',\n",
       " 'so',\n",
       " 'sp',\n",
       " 'ss',\n",
       " 'st',\n",
       " 't ',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'th',\n",
       " 'ti',\n",
       " 'tl',\n",
       " 'to',\n",
       " 'tp',\n",
       " 'tr',\n",
       " 'ts',\n",
       " 'tt',\n",
       " 'tu',\n",
       " 'ty',\n",
       " 'ua',\n",
       " 'ue',\n",
       " 'ul',\n",
       " 'un',\n",
       " 'ur',\n",
       " 'us',\n",
       " 'ut',\n",
       " 'va',\n",
       " 've',\n",
       " 'vi',\n",
       " 'vo',\n",
       " 'w ',\n",
       " 'wa',\n",
       " 'we',\n",
       " 'wh',\n",
       " 'wi',\n",
       " 'wn',\n",
       " 'x ',\n",
       " 'xa',\n",
       " 'xc',\n",
       " 'xp',\n",
       " 'y ',\n",
       " 'ye',\n",
       " 'yl',\n",
       " 'ym',\n",
       " 'yt'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct different k-grams based on different criteria\n",
    "\n",
    "# function that generates 2 character k grams\n",
    "def generate_2_character_gram(document):\n",
    "    print(\"The 2-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    two_char_gram_set = set()\n",
    "    \n",
    "    for i in range(0, len(document) - 1):\n",
    "        two_char_string = \"\"\n",
    "        char_1 = document[i]\n",
    "        char_2 = document[i + 1]\n",
    "        two_char_string += char_1 + char_2\n",
    "        two_char_gram_set.add(two_char_string)\n",
    "#         print(two_char_string)\n",
    "\n",
    "    # determine the number of characters in the document\n",
    "    print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return two_char_gram_set\n",
    "\n",
    "# function that generates 3 character k grams\n",
    "def generate_3_character_gram(document):\n",
    "    print(\"The 3-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    three_char_gram_set = set()\n",
    "    \n",
    "    # determine the number of characters in the document\n",
    "    print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return three_char_gram_set\n",
    "\n",
    "# function that generates 2 word k grams\n",
    "def generate_2_word_gram(document):\n",
    "    print(\"The 2-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    two_word_gram_set = set()\n",
    "    \n",
    "    # determine the number of characters in the document\n",
    "    print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return two_word_gram_set\n",
    "\n",
    "generate_2_character_gram(doc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n"
     ]
    }
   ],
   "source": [
    "foo = set()\n",
    "foo.add(1)\n",
    "print(foo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
