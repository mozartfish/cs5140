{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some stuff\n",
    "import numpy as np\n",
    "import math\n",
    "import time as time\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and store documents\n",
    "def document_reader(file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    if (f.mode == \"r\"):\n",
    "        contents = f.read()\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a set of functions that generates k grams based on different criteria\n",
    "#  and the jaccardian similiary between documents\n",
    "\n",
    "# construct different k-grams based on different criteria\n",
    "\n",
    "# function that generates 2 character k grams\n",
    "def generate_2_character_gram(document):\n",
    "    print(\"The 2-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    two_char_gram_set = set()\n",
    "    \n",
    "    for i in range(0, len(document) - 1):\n",
    "        two_char_string = \"\"\n",
    "        char_1 = document[i]\n",
    "#         print(char_1)\n",
    "        char_2 = document[i + 1]\n",
    "#         print(char_2)\n",
    "        two_char_string += char_1 + char_2\n",
    "#         print(two_char_string)\n",
    "        two_char_gram_set.add(two_char_string)\n",
    "\n",
    "\n",
    "    # determine the number of characters in the document\n",
    "#     print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return two_char_gram_set\n",
    "\n",
    "# function that generates 3 character k grams\n",
    "def generate_3_character_gram(document):\n",
    "    print(\"The 3-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    three_char_gram_set = set()\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    three_char_gram_set = set()\n",
    "    \n",
    "    for j in range(0, len(document) - 2):\n",
    "        three_char_string = \"\"\n",
    "        char_1 = document[j]\n",
    "#         print(char_1)\n",
    "        char_2 = document[j + 1]\n",
    "#         print(char_2)\n",
    "        char_3 = document[j + 2]\n",
    "#         print(char_3)\n",
    "        three_char_string += char_1 + char_2 + char_3\n",
    "#         print(three_char_string)\n",
    "        three_char_gram_set.add(three_char_string)\n",
    "\n",
    "        \n",
    "    \n",
    "    # determine the number of characters in the document\n",
    "#     print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return three_char_gram_set\n",
    "\n",
    "# function that generates 2 word k grams\n",
    "def generate_2_word_gram(document):\n",
    "    print(\"The 2-gram based on words\")\n",
    "    \n",
    "    # split the document into tokens (words)\n",
    "    document_words = document.split()\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    two_word_gram_set = set()\n",
    "    \n",
    "    # use the same logic from generate_2_character_gram function to construct the grams\n",
    "    for h in range(0, len(document_words) - 2):\n",
    "        two_word_string = \"\"\n",
    "        word_1 = document_words[h]\n",
    "#         print(word_1)\n",
    "        word_2 = document_words[h + 1]\n",
    "#         print(word_2)\n",
    "        two_word_string += word_1 + \" \" + word_2\n",
    "#         print(two_word_string)\n",
    "        two_word_gram_set.add(two_word_string)\n",
    "\n",
    "    return two_word_gram_set\n",
    "\n",
    "def jaccardian_similarity(a, b):\n",
    "    # compute the intersection of a and b\n",
    "    a_intersect_b = a.intersection(b)\n",
    "    \n",
    "    # compute the magnitude of the intersection of a intersect b\n",
    "    a_intersect_b_magnitude = len(a_intersect_b)\n",
    "    \n",
    "    # compute the union of a and b\n",
    "    a_union_b = a.union(b)\n",
    "    \n",
    "    # compute the magnitude of the union of a and b\n",
    "    a_union_b_magnitude = len(a_union_b)\n",
    "    \n",
    "    similarity = a_intersect_b_magnitude / a_union_b_magnitude\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2-gram based on characters\n",
      "The 2-gram based on characters\n",
      "The 2-gram based on characters\n",
      "The 2-gram based on characters\n",
      "The 3-gram based on characters\n",
      "The 3-gram based on characters\n",
      "The 3-gram based on characters\n",
      "The 3-gram based on characters\n",
      "The 2-gram based on words\n",
      "The 2-gram based on words\n",
      "The 2-gram based on words\n",
      "The 2-gram based on words\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "# Part A\n",
    "\n",
    "# Read documents\n",
    "doc_1 = document_reader(\"D1.txt\")\n",
    "doc_2 = document_reader(\"D2.txt\")\n",
    "doc_3 = document_reader(\"D3.txt\")\n",
    "doc_4 = document_reader(\"D4.txt\")\n",
    "\n",
    "# print statements for debugging the documents\n",
    "# print(doc_1)\n",
    "# print(doc_2)\n",
    "# print(doc_3)\n",
    "# print(doc_4)\n",
    "\n",
    "# Generate the different 2 character grams for the documents\n",
    "doc_1_2_char_gram = generate_2_character_gram(doc_1)\n",
    "doc_2_2_char_gram = generate_2_character_gram(doc_2)\n",
    "doc_3_2_char_gram = generate_2_character_gram(doc_3)\n",
    "doc_4_2_char_gram = generate_2_character_gram(doc_4)\n",
    "\n",
    "# Generate the different 3 character grams for the documents\n",
    "doc_1_3_char_gram = generate_3_character_gram(doc_1)\n",
    "doc_2_3_char_gram = generate_3_character_gram(doc_2)\n",
    "doc_3_3_char_gram = generate_3_character_gram(doc_3)\n",
    "doc_4_3_char_gram = generate_3_character_gram(doc_4)\n",
    "\n",
    "# Generate the different 2 word grams for the documents\n",
    "doc_1_2_word_gram = generate_2_word_gram(doc_1)\n",
    "doc_2_2_word_gram = generate_2_word_gram(doc_2)\n",
    "doc_3_2_word_gram = generate_2_word_gram(doc_3)\n",
    "doc_4_2_word_gram = generate_2_word_gram(doc_4)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
