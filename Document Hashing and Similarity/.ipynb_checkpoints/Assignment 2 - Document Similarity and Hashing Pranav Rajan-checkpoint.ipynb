{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some stuff\n",
    "import numpy as np\n",
    "import math\n",
    "import time as time\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and store documents\n",
    "def document_reader(file_name):\n",
    "    f = open(file_name, \"r\")\n",
    "    if (f.mode == \"r\"):\n",
    "        contents = f.read()\n",
    "        return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a set of functions that generates k grams based on different criteria\n",
    "#  and the jaccardian similiary between documents\n",
    "\n",
    "# construct different k-grams based on different criteria\n",
    "\n",
    "# function that generates 2 character k grams\n",
    "def generate_2_character_gram(document):\n",
    "#     print(\"The 2-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    two_char_gram_set = set()\n",
    "    \n",
    "    for i in range(0, len(document) - 1):\n",
    "        two_char_string = \"\"\n",
    "        char_1 = document[i]\n",
    "#         print(char_1)\n",
    "        char_2 = document[i + 1]\n",
    "#         print(char_2)\n",
    "        two_char_string += char_1 + char_2\n",
    "#         print(two_char_string)\n",
    "        two_char_gram_set.add(two_char_string)\n",
    "\n",
    "\n",
    "    # determine the number of characters in the document\n",
    "#     print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return two_char_gram_set\n",
    "\n",
    "# function that generates 3 character k grams\n",
    "def generate_3_character_gram(document):\n",
    "#     print(\"The 3-gram based on characters\")\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    three_char_gram_set = set()\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    three_char_gram_set = set()\n",
    "    \n",
    "    for j in range(0, len(document) - 2):\n",
    "        three_char_string = \"\"\n",
    "        char_1 = document[j]\n",
    "#         print(char_1)\n",
    "        char_2 = document[j + 1]\n",
    "#         print(char_2)\n",
    "        char_3 = document[j + 2]\n",
    "#         print(char_3)\n",
    "        three_char_string += char_1 + char_2 + char_3\n",
    "#         print(three_char_string)\n",
    "        three_char_gram_set.add(three_char_string)\n",
    "\n",
    "        \n",
    "    \n",
    "    # determine the number of characters in the document\n",
    "#     print(\"The number of characters in the document:\", len(document))\n",
    "    \n",
    "    return three_char_gram_set\n",
    "\n",
    "# function that generates 2 word k grams\n",
    "def generate_2_word_gram(document):\n",
    "#     print(\"The 2-gram based on words\")\n",
    "    \n",
    "    # split the document into tokens (words)\n",
    "    document_words = document.split()\n",
    "    \n",
    "    # set to ensure that there are no duplicates\n",
    "    two_word_gram_set = set()\n",
    "    \n",
    "    # use the same logic from generate_2_character_gram function to construct the grams\n",
    "    for h in range(0, len(document_words) - 1):\n",
    "        two_word_string = \"\"\n",
    "        word_1 = document_words[h]\n",
    "#         print(word_1)\n",
    "        word_2 = document_words[h + 1]\n",
    "#         print(word_2)\n",
    "        two_word_string += word_1 + \" \" + word_2\n",
    "#         print(two_word_string)\n",
    "        two_word_gram_set.add(two_word_string)\n",
    "\n",
    "    return two_word_gram_set\n",
    "\n",
    "def jaccardian_similarity(a, b):\n",
    "#     print(\"The jaccardian similarity between a and b\")\n",
    "    # compute the intersection of a and b\n",
    "    a_intersect_b = a.intersection(b)\n",
    "    \n",
    "    # compute the magnitude of the intersection of a intersect b\n",
    "    a_intersect_b_magnitude = len(a_intersect_b)\n",
    "    \n",
    "    # compute the union of a and b\n",
    "    a_union_b = a.union(b)\n",
    "    \n",
    "    # compute the magnitude of the union of a and b\n",
    "    a_union_b_magnitude = len(a_union_b)\n",
    "    \n",
    "    similarity = a_intersect_b_magnitude / a_union_b_magnitude\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of distinct 2 character grams for document 1: 266\n",
      "The number of distinct 2 character grams for document 2: 264\n",
      "The number of distinct 2 character grams for document 3: 296\n",
      "The number of distinct 2 character grams for document 4: 249\n",
      "\n",
      "The number of distinct 3 character grams for document 1: 770\n",
      "The number of distinct 3 character grams for document 2: 759\n",
      "The number of distinct 3 character grams for document 3: 978\n",
      "The number of distinct 3 character grams for document 4: 770\n",
      "\n",
      "The number of distinct 2 word grams for document 1: 289\n",
      "The number of distinct 2 word grams for document 2: 297\n",
      "The number of distinct 2 word grams for document 3: 390\n",
      "The number of distinct 2 word grams for document 4: 364\n",
      "\n",
      "The jaccardian similarity for 2 character grams for document 1 and document 2: 0.9924812030075187\n",
      "The jaccardian similarity for 2 character grams for document 1 and docuemnt 3: 0.7841269841269841\n",
      "The jaccardian similarity for 2 character grams for document 1 and document 4: 0.6666666666666666\n",
      "The jaccardian similarity for 2 character grams for document 2 and document 3: 0.7834394904458599\n",
      "The jaccardian similarity for 2 character grams for document 2 and document 4: 0.6601941747572816\n",
      "The jaccardian similarity for 2 character grams for document 3 and document 4: 0.6717791411042945\n",
      "\n",
      "The jaccardian similarity for 3 character grams for document 1 and document 2: 0.9552429667519181\n",
      "The jaccardian similarity for 3 character grams for document 1 and document 3: 0.5030094582975064\n",
      "The jaccardian similarity for 3 character grams for document 1 and document 4: 0.3061916878710772\n",
      "The jaccardian similarity for 3 character grams for document 2 and document 3: 0.4987057808455565\n",
      "The jaccardian similarity for 3 character grams for document 2 and document 4: 0.3034953111679454\n",
      "The jaccardian similarity for 3 character grams for document 3 and document 4: 0.31329827197595794\n",
      "\n",
      "The jaccardian similarity for 2 word grams for document 1 and document 2: 0.7920489296636085\n",
      "The jaccardian similarity for 2 word grams for document 1 and document 3: 0.1954225352112676\n",
      "The jaccardian similarity for 2 word grams for document 1 and document 4: 0.007716049382716049\n",
      "The jaccardian similarity for 2 word grams for document 2 and document 3: 0.17636986301369864\n",
      "The jaccardian similarity for 2 word grams for document 2 and document 4: 0.00916030534351145\n",
      "The jaccardian similarity for 2 word grams for document 3 and document 4: 0.012080536912751677\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "\n",
    "# Read documents\n",
    "doc_1 = document_reader(\"D1.txt\")\n",
    "doc_2 = document_reader(\"D2.txt\")\n",
    "doc_3 = document_reader(\"D3.txt\")\n",
    "doc_4 = document_reader(\"D4.txt\")\n",
    "\n",
    "# print statements for debugging the documents\n",
    "# print(doc_1)\n",
    "# print(doc_2)\n",
    "# print(doc_3)\n",
    "# print(doc_4)\n",
    "\n",
    "# Generate the different 2 character grams for the documents\n",
    "doc_1_2_char_gram = generate_2_character_gram(doc_1)\n",
    "doc_2_2_char_gram = generate_2_character_gram(doc_2)\n",
    "doc_3_2_char_gram = generate_2_character_gram(doc_3)\n",
    "doc_4_2_char_gram = generate_2_character_gram(doc_4)\n",
    "\n",
    "# Generate the different 3 character grams for the documents\n",
    "doc_1_3_char_gram = generate_3_character_gram(doc_1)\n",
    "doc_2_3_char_gram = generate_3_character_gram(doc_2)\n",
    "doc_3_3_char_gram = generate_3_character_gram(doc_3)\n",
    "doc_4_3_char_gram = generate_3_character_gram(doc_4)\n",
    "\n",
    "# Generate the different 2 word grams for the documents\n",
    "doc_1_2_word_gram = generate_2_word_gram(doc_1)\n",
    "doc_2_2_word_gram = generate_2_word_gram(doc_2)\n",
    "doc_3_2_word_gram = generate_2_word_gram(doc_3)\n",
    "doc_4_2_word_gram = generate_2_word_gram(doc_4)\n",
    "\n",
    "# Compute the jaccardian similarity between the documents\n",
    "\n",
    "# 2 character gram similarities\n",
    "doc1_doc2_2_char = jaccardian_similarity(doc_1_2_char_gram, doc_2_2_char_gram)\n",
    "doc1_doc3_2_char = jaccardian_similarity(doc_1_2_char_gram, doc_3_2_char_gram)\n",
    "doc1_doc4_2_char = jaccardian_similarity(doc_1_2_char_gram, doc_4_2_char_gram)\n",
    "doc2_doc3_2_char = jaccardian_similarity(doc_2_2_char_gram, doc_3_2_char_gram)\n",
    "doc2_doc4_2_char = jaccardian_similarity(doc_2_2_char_gram, doc_4_2_char_gram)\n",
    "doc3_doc4_2_char = jaccardian_similarity(doc_3_2_char_gram, doc_4_2_char_gram)\n",
    "\n",
    "# 3 character gram similarities\n",
    "doc1_doc2_3_char = jaccardian_similarity(doc_1_3_char_gram, doc_2_3_char_gram)\n",
    "doc1_doc3_3_char = jaccardian_similarity(doc_1_3_char_gram, doc_3_3_char_gram)\n",
    "doc1_doc4_3_char = jaccardian_similarity(doc_1_3_char_gram, doc_4_3_char_gram)\n",
    "doc2_doc3_3_char = jaccardian_similarity(doc_2_3_char_gram, doc_3_3_char_gram)\n",
    "doc2_doc4_3_char = jaccardian_similarity(doc_2_3_char_gram, doc_4_3_char_gram)\n",
    "doc3_doc4_3_char = jaccardian_similarity(doc_3_3_char_gram, doc_4_3_char_gram)\n",
    "\n",
    "# 2 word gram similarities\n",
    "doc1_doc2_2_word = jaccardian_similarity(doc_1_2_word_gram, doc_2_2_word_gram)\n",
    "doc1_doc3_2_word = jaccardian_similarity(doc_1_2_word_gram, doc_3_2_word_gram)\n",
    "doc1_doc4_2_word = jaccardian_similarity(doc_1_2_word_gram, doc_4_2_word_gram)\n",
    "doc2_doc3_2_word = jaccardian_similarity(doc_2_2_word_gram, doc_3_2_word_gram)\n",
    "doc2_doc4_2_word = jaccardian_similarity(doc_2_2_word_gram, doc_4_2_word_gram)\n",
    "doc3_doc4_2_word = jaccardian_similarity(doc_3_2_word_gram, doc_4_2_word_gram)\n",
    "\n",
    "# Generate the results\n",
    "print(f\"The number of distinct 2 character grams for document 1: {len(doc_1_2_char_gram)}\")\n",
    "print(f\"The number of distinct 2 character grams for document 2: {len(doc_2_2_char_gram)}\")\n",
    "print(f\"The number of distinct 2 character grams for document 3: {len(doc_3_2_char_gram)}\")\n",
    "print(f\"The number of distinct 2 character grams for document 4: {len(doc_4_2_char_gram)}\")\n",
    "print()\n",
    "print(f\"The number of distinct 3 character grams for document 1: {len(doc_1_3_char_gram)}\")\n",
    "print(f\"The number of distinct 3 character grams for document 2: {len(doc_2_3_char_gram)}\")\n",
    "print(f\"The number of distinct 3 character grams for document 3: {len(doc_3_3_char_gram)}\")\n",
    "print(f\"The number of distinct 3 character grams for document 4: {len(doc_4_3_char_gram)}\")\n",
    "print()\n",
    "print(f\"The number of distinct 2 word grams for document 1: {len(doc_1_2_word_gram)}\")\n",
    "print(f\"The number of distinct 2 word grams for document 2: {len(doc_2_2_word_gram)}\")\n",
    "print(f\"The number of distinct 2 word grams for document 3: {len(doc_3_2_word_gram)}\")\n",
    "print(f\"The number of distinct 2 word grams for document 4: {len(doc_4_2_word_gram)}\")\n",
    "print()\n",
    "print(f\"The jaccardian similarity for 2 character grams for document 1 and document 2: {doc1_doc2_2_char}\")\n",
    "print(f\"The jaccardian similarity for 2 character grams for document 1 and docuemnt 3: {doc1_doc3_2_char}\")\n",
    "print(f\"The jaccardian similarity for 2 character grams for document 1 and document 4: {doc1_doc4_2_char}\")\n",
    "print(f\"The jaccardian similarity for 2 character grams for document 2 and document 3: {doc2_doc3_2_char}\")\n",
    "print(f\"The jaccardian similarity for 2 character grams for document 2 and document 4: {doc2_doc4_2_char}\")\n",
    "print(f\"The jaccardian similarity for 2 character grams for document 3 and document 4: {doc3_doc4_2_char}\")\n",
    "print()\n",
    "print(f\"The jaccardian similarity for 3 character grams for document 1 and document 2: {doc1_doc2_3_char}\")\n",
    "print(f\"The jaccardian similarity for 3 character grams for document 1 and document 3: {doc1_doc3_3_char}\")\n",
    "print(f\"The jaccardian similarity for 3 character grams for document 1 and document 4: {doc1_doc4_3_char}\")\n",
    "print(f\"The jaccardian similarity for 3 character grams for document 2 and document 3: {doc2_doc3_3_char}\")\n",
    "print(f\"The jaccardian similarity for 3 character grams for document 2 and document 4: {doc2_doc4_3_char}\")\n",
    "print(f\"The jaccardian similarity for 3 character grams for document 3 and document 4: {doc3_doc4_3_char}\")\n",
    "print()\n",
    "print(f\"The jaccardian similarity for 2 word grams for document 1 and document 2: {doc1_doc2_2_word}\")\n",
    "print(f\"The jaccardian similarity for 2 word grams for document 1 and document 3: {doc1_doc3_2_word}\")\n",
    "print(f\"The jaccardian similarity for 2 word grams for document 1 and document 4: {doc1_doc4_2_word}\")\n",
    "print(f\"The jaccardian similarity for 2 word grams for document 2 and document 3: {doc2_doc3_2_word}\")\n",
    "print(f\"The jaccardian similarity for 2 word grams for document 2 and document 4: {doc2_doc4_2_word}\")\n",
    "print(f\"The jaccardian similarity for 2 word grams for document 3 and document 4: {doc3_doc4_2_word}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
