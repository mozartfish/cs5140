{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some stuff\n",
    "from numpy import linalg as LA\n",
    "import numpy as np \n",
    "import pandas\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (100, 50)\n",
      "The shape of Y is: (100,)\n",
      "The shape of M is: (50, 20)\n",
      "The shape of W is: (50,)\n"
     ]
    }
   ],
   "source": [
    "# read in the data \n",
    "X = np.loadtxt('X.csv', delimiter=',')\n",
    "y = np.loadtxt('y.csv', delimiter=',')\n",
    "M = np.loadtxt('M.csv', delimiter=',')\n",
    "W = np.loadtxt('W.csv', delimiter=',')\n",
    "\n",
    "# Shape of the data\n",
    "x_shape = X.shape\n",
    "y_shape = y.shape\n",
    "m_shape = M.shape\n",
    "w_shape = W.shape\n",
    "\n",
    "print(f\"The shape of X is: {x_shape}\")\n",
    "print(f\"The shape of Y is: {y_shape}\")\n",
    "print(f\"The shape of M is: {m_shape}\")\n",
    "print(f\"The shape of W is: {w_shape}\")\n",
    "\n",
    "#Test to see if some stuff is read correctly\n",
    "# print(X)\n",
    "# print(y)\n",
    "# print(M)\n",
    "# print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of X are: (100, 50)\n",
      "The dimensions of Y are: (100,)\n",
      "The sum of square error for least squares is: 3.4727000180303693\n",
      "\n",
      "The error for ridge regression for s value: 0.2 is : 3.8730952721774807\n",
      "The error for ridge regression for s value: 0.4 is : 4.033682435987204\n",
      "The error for ridge regression for s value: 0.8 is : 4.3048123710580875\n",
      "The error for ridge regression for s value: 1.0 is : 4.424875280272593\n",
      "The error for ridge regression for s value: 1.2 is : 4.536675515386759\n",
      "The error for ridge regression for s value: 1.4 is : 4.64122029603989\n",
      "The error for ridge regression for s value: 1.6 is : 4.739335579394492\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART A\n",
    "\n",
    "# Get the shape information about the X matrix and the least squares alpha \n",
    "x_shape = X.shape\n",
    "y_shape = y.shape\n",
    "print(f\"The dimensions of X are: {x_shape}\")\n",
    "print(f\"The dimensions of Y are: {y_shape}\")\n",
    "\n",
    "# LEAST SQUARES\n",
    "# function that computes alpha values for least squares\n",
    "def least_squares(X, y):\n",
    "    alpha = LA.inv(X.T @ X) @ X.T @ y.T\n",
    "    return alpha\n",
    "\n",
    "ls_alpha = least_squares(X, y)\n",
    "ls_error = LA.norm(y - X.dot(ls_alpha),2)\n",
    "print(f\"The sum of square error for least squares is: {ls_error}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Ridge Regression\n",
    "s = [0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6]\n",
    "# function that computes alpha values for ridge regression for a particular s value\n",
    "def ridge(X, y, s):\n",
    "    alpha = LA.inv(X.T @ X + s * np.identity(50)) @ X.T @ y.T\n",
    "    return alpha \n",
    "\n",
    "for j in s:\n",
    "    ridge_alpha = ridge(X, y, j)\n",
    "    ridge_error = LA.norm(y - X.dot(ridge_alpha),2)\n",
    "    print(f\"The error for ridge regression for s value: {j} is : {ridge_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions for X1 TRAIN are: (66, 50)\n",
      "The dimensions for Y1 TRAIN are: (66,)\n",
      "The dimensions for X1 TEST are: (34, 50)\n",
      "The dimensions for Y1 TEST are: (34,)\n",
      "\n",
      "The sum of square error for least squares is: 6.353856761905907\n",
      "\n",
      "The error for ridge regression for s value: 0.2 is : 3.5426140853239767\n",
      "The error for ridge regression for s value: 0.4 is : 3.4232354642931604\n",
      "The error for ridge regression for s value: 0.8 is : 3.408309638731431\n",
      "The error for ridge regression for s value: 1.0 is : 3.4290811065906213\n",
      "The error for ridge regression for s value: 1.2 is : 3.455310381091074\n",
      "The error for ridge regression for s value: 1.4 is : 3.483786649135729\n",
      "The error for ridge regression for s value: 1.6 is : 3.5129443876932482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART B FOR X1, Y1\n",
    "\n",
    "# SLICE THE DATA according to the homework instructions\n",
    "# TRAINING DATA\n",
    "X1 = X[:66, :]\n",
    "Y1 = y[:66]\n",
    "\n",
    "# TESTING DATA\n",
    "X1_Test = X[66:, :]\n",
    "Y1_Test = y[66:]\n",
    "\n",
    "x1_shape = X1.shape\n",
    "y1_shape = Y1.shape\n",
    "x1_test_shape = X1_Test.shape\n",
    "y1_test_shape = Y1_Test.shape\n",
    "print(f\"The dimensions for X1 TRAIN are: {x1_shape}\")\n",
    "print(f\"The dimensions for Y1 TRAIN are: {y1_shape}\")\n",
    "print(f\"The dimensions for X1 TEST are: {x1_test_shape}\")\n",
    "print(f\"The dimensions for Y1 TEST are: {y1_test_shape}\")\n",
    "print()\n",
    "\n",
    "# LEAST SQUARES\n",
    "# function that computes alpha values for least squares\n",
    "def least_squares(X, y):\n",
    "    alpha = LA.inv(X.T @ X) @ X.T @ y.T\n",
    "    return alpha\n",
    "\n",
    "# Ridge Regression\n",
    "s = [0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6]\n",
    "# function that computes alpha values for ridge regression for a particular s value\n",
    "def ridge(X, y, s):\n",
    "    alpha = LA.inv(X.T @ X + s * np.identity(50)) @ X.T @ y.T\n",
    "    return alpha \n",
    "\n",
    "ls_alpha = least_squares(X1, Y1)\n",
    "ls_error = LA.norm(Y1_Test - X1_Test.dot(ls_alpha),2)\n",
    "print(f\"The sum of square error for least squares is: {ls_error}\")\n",
    "print()\n",
    "\n",
    "for k in s:\n",
    "    ridge_alpha = ridge(X1, Y1, k)\n",
    "    ridge_error = LA.norm(Y1_Test - X1_Test.dot(ridge_alpha),2)\n",
    "    print(f\"The error for ridge regression for s value: {k} is : {ridge_error}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions for X2 TRAIN are: (67, 50)\n",
      "The dimensions for Y2 TRAIN  are: (67,)\n",
      "The dimensions for X2 TEST are: (33, 50)\n",
      "The dimensions for Y2 TEST are: (33,)\n",
      "\n",
      "The sum of square error for least squares is: 4.8525076846268105\n",
      "\n",
      "The error for ridge regression for s value: 0.2 is : 3.0359446535958092\n",
      "The error for ridge regression for s value: 0.4 is : 3.134538681197435\n",
      "The error for ridge regression for s value: 0.8 is : 3.338743802949011\n",
      "The error for ridge regression for s value: 1.0 is : 3.4262586794500938\n",
      "The error for ridge regression for s value: 1.2 is : 3.5051933148002683\n",
      "The error for ridge regression for s value: 1.4 is : 3.576849716582565\n",
      "The error for ridge regression for s value: 1.6 is : 3.642321027650595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART B FOR X2, Y2\n",
    "\n",
    "# SLICE THE DATA according to the homework instructions\n",
    "# TRAINING DATA\n",
    "X2 = X[33:, :]\n",
    "Y2 = y[33:]\n",
    "\n",
    "# TESTING DATA\n",
    "X2_Test = X[:33, :]\n",
    "Y2_Test = y[:33]\n",
    "\n",
    "x2_shape = X2.shape\n",
    "y2_shape = Y2.shape\n",
    "x2_test_shape = X2_Test.shape\n",
    "y2_test_shape = Y2_Test.shape\n",
    "print(f\"The dimensions for X2 TRAIN are: {x2_shape}\")\n",
    "print(f\"The dimensions for Y2 TRAIN  are: {y2_shape}\")\n",
    "print(f\"The dimensions for X2 TEST are: {x2_test_shape}\")\n",
    "print(f\"The dimensions for Y2 TEST are: {y2_test_shape}\")\n",
    "print()\n",
    "\n",
    "# LEAST SQUARES\n",
    "# function that computes alpha values for least squares\n",
    "def least_squares(X, y):\n",
    "    alpha = LA.inv(X.T @ X) @ X.T @ y.T\n",
    "    return alpha\n",
    "\n",
    "# Ridge Regression\n",
    "s = [0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6]\n",
    "# function that computes alpha values for ridge regression for a particular s value\n",
    "def ridge(X, y, s):\n",
    "    alpha = LA.inv(X.T @ X + s * np.identity(50)) @ X.T @ y.T\n",
    "    return alpha \n",
    "\n",
    "ls_alpha = least_squares(X2, Y2)\n",
    "ls_error = LA.norm(Y2_Test - X2_Test.dot(ls_alpha), 2)\n",
    "print(f\"The sum of square error for least squares is: {ls_error}\")\n",
    "print()\n",
    "\n",
    "for i in s:\n",
    "    ridge_alpha = ridge(X2, Y2, i)\n",
    "    ridge_error = LA.norm(Y2_Test - X2_Test.dot(ridge_alpha),2)\n",
    "    print(f\"The error for ridge regression for s value: {i} is : {ridge_error}\")\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions for X3 TRAIN are: (67, 50)\n",
      "The dimensions for Y3 TRAIN  are: (67,)\n",
      "The dimensions for X3 TEST are: (33, 50)\n",
      "The dimensions for Y3 TEST are: (33,)\n",
      "\n",
      "The sum of square error for least squares is: 4.482920325377559\n",
      "\n",
      "The error for ridge regression for s value: 0.2 is : 2.6925279657036123\n",
      "The error for ridge regression for s value: 0.4 is : 2.5187834397580797\n",
      "The error for ridge regression for s value: 0.8 is : 2.4765682425684017\n",
      "The error for ridge regression for s value: 1.0 is : 2.499792609238205\n",
      "The error for ridge regression for s value: 1.2 is : 2.5337329506933446\n",
      "The error for ridge regression for s value: 1.4 is : 2.5731752773381107\n",
      "The error for ridge regression for s value: 1.6 is : 2.6152599698036934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART B FOR X3, Y3\n",
    "\n",
    "# SLICE THE DATA according to the homework instructions\n",
    "# TRAINING DATA \n",
    "X3 = np.concatenate((X[:33,:], X[66:,:]))\n",
    "Y3 = np.concatenate((y[:33], y[66:]))\n",
    "\n",
    "# TESTING DATA\n",
    "X3_Test = X[33:66, :]\n",
    "Y3_Test = y[33:66]\n",
    "x3_shape = X3.shape\n",
    "y3_shape = Y3.shape\n",
    "x3_test_shape = X3_Test.shape\n",
    "y3_test_shape = Y3_Test.shape\n",
    "print(f\"The dimensions for X3 TRAIN are: {x3_shape}\")\n",
    "print(f\"The dimensions for Y3 TRAIN  are: {y3_shape}\")\n",
    "print(f\"The dimensions for X3 TEST are: {x3_test_shape}\")\n",
    "print(f\"The dimensions for Y3 TEST are: {y3_test_shape}\")\n",
    "print()\n",
    "\n",
    "# LEAST SQUARES\n",
    "# function that computes alpha values for least squares\n",
    "def least_squares(X, y):\n",
    "    alpha = LA.inv(X.T @ X) @ X.T @ y.T\n",
    "    return alpha\n",
    "\n",
    "# Ridge Regression\n",
    "s = [0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6]\n",
    "# function that computes alpha values for ridge regression for a particular s value\n",
    "def ridge(X, y, s):\n",
    "    alpha = LA.inv(X.T @ X + s * np.identity(50)) @ X.T @ y.T\n",
    "    return alpha \n",
    "\n",
    "ls_alpha = least_squares(X3, Y3)\n",
    "ls_error = LA.norm(Y3_Test - X3_Test.dot(ls_alpha), 2)\n",
    "print(f\"The sum of square error for least squares is: {ls_error}\")\n",
    "print()\n",
    "\n",
    "for h in s:\n",
    "    ridge_alpha = ridge(X3, Y3, h)\n",
    "    ridge_error = LA.norm(Y3_Test - X3_Test.dot(ridge_alpha),2)\n",
    "    print(f\"The error for ridge regression for s value: {h} is : {ridge_error}\")\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error for least squares is: 5.229761590636759\n",
      "\n",
      "The average error for ridge regression\n",
      "The average error for 0.2 is: 3.090362234874466\n",
      "The average error for 0.4 is: 3.0255191950828917\n",
      "The average error for 0.8 is: 3.0745405614162813\n",
      "The average error for 1.0 is: 3.118377465092973\n",
      "The average error for 1.2 is: 3.1647455488615623\n",
      "The average error for 1.4 is: 3.211270547685468\n",
      "The average error for 1.6 is: 3.2568417950491786\n"
     ]
    }
   ],
   "source": [
    "# QUESTION 1 PART C\n",
    "\n",
    "# LEAST SQUARES\n",
    "# function that computes alpha values for least squares\n",
    "def least_squares(X, y):\n",
    "    alpha = LA.inv(X.T @ X) @ X.T @ y.T\n",
    "    return alpha\n",
    "\n",
    "# Ridge Regression\n",
    "s = [0.2, 0.4, 0.8, 1.0, 1.2, 1.4, 1.6]\n",
    "# function that computes alpha values for ridge regression for a particular s value\n",
    "def ridge(X, y, s):\n",
    "    alpha = LA.inv(X.T @ X + s * np.identity(50)) @ X.T @ y.T\n",
    "    return alpha \n",
    "\n",
    "def least_squares_average():\n",
    "    # list for storing the result\n",
    "    result = []\n",
    "    \n",
    "    # TRAINING DATA\n",
    "    X1 = X[:66, :]\n",
    "    Y1 = y[:66]\n",
    "    X2 = X[33:, :]\n",
    "    Y2 = y[33:]\n",
    "    X3 = np.concatenate((X[:33,:], X[66:,:]))\n",
    "    Y3 = np.concatenate((y[:33], y[66:]))\n",
    "    \n",
    "    # TESTING DATA\n",
    "    X1_Test = X[66:, :]\n",
    "    Y1_Test = y[66:]\n",
    "    X2_Test = X[:33, :]\n",
    "    Y2_Test = y[:33]\n",
    "    X3_Test = X[33:66, :]\n",
    "    Y3_Test = y[33:66] \n",
    "    \n",
    "    # get the alpha values for the different data \n",
    "    ls_alpha_1 = least_squares(X1, Y1)\n",
    "    ls_alpha_2 = least_squares(X2, Y2)\n",
    "    ls_alpha_3 = least_squares(X3, Y3)\n",
    "    \n",
    "    # calculate the error for the different data\n",
    "    ls_error_1 = LA.norm(Y1_Test - X1_Test.dot(ls_alpha_1), 2)\n",
    "    ls_error_2 = LA.norm(Y2_Test - X2_Test.dot(ls_alpha_2), 2)\n",
    "    ls_error_3 = LA.norm(Y3_Test - X3_Test.dot(ls_alpha_3), 2)\n",
    "    \n",
    "    result.append(ls_error_1)\n",
    "    result.append(ls_error_2)\n",
    "    result.append(ls_error_3)\n",
    "    \n",
    "    return np.average(result)\n",
    "\n",
    "def ridge_average ():\n",
    "    # lists for storing the result\n",
    "    result_0 = []\n",
    "    result_1 = []\n",
    "    result_2 = []\n",
    "    result_3 = []\n",
    "    result_4 = []\n",
    "    result_5 = []\n",
    "    result_6 = []\n",
    "    \n",
    "    # TRAINING DATA\n",
    "    X1 = X[:66, :]\n",
    "    Y1 = y[:66]\n",
    "    X2 = X[33:, :]\n",
    "    Y2 = y[33:]\n",
    "    X3 = np.concatenate((X[:33,:], X[66:,:]))\n",
    "    Y3 = np.concatenate((y[:33], y[66:]))\n",
    "    \n",
    "    # TESTING DATA\n",
    "    X1_Test = X[66:, :]\n",
    "    Y1_Test = y[66:]\n",
    "    X2_Test = X[:33, :]\n",
    "    Y2_Test = y[:33]\n",
    "    X3_Test = X[33:66, :]\n",
    "    Y3_Test = y[33:66] \n",
    "    \n",
    "    # counter for keeping track of iterations\n",
    "    counter = 0\n",
    "    while counter < 7:\n",
    "        # get the current s value\n",
    "        s_value = s[counter]\n",
    "        \n",
    "        # compute the ridge alpha values for the particular s value\n",
    "        ridge_alpha_1 = ridge(X1, Y1, s_value)\n",
    "        ridge_alpha_2 = ridge(X2, Y2, s_value)\n",
    "        ridge_alpha_3 = ridge(X3, Y3, s_value)\n",
    "        \n",
    "        # compute the error for the different data\n",
    "        ridge_error_1 = LA.norm(Y1_Test - X1_Test.dot(ridge_alpha_1), 2)\n",
    "        ridge_error_2 = LA.norm(Y2_Test - X2_Test.dot(ridge_alpha_2), 2)\n",
    "        ridge_error_3 = LA.norm(Y3_Test - X3_Test.dot(ridge_alpha_3), 2)\n",
    "        \n",
    "        if counter == 0:\n",
    "            result_0.append(ridge_error_1)\n",
    "            result_0.append(ridge_error_2)\n",
    "            result_0.append(ridge_error_3)\n",
    "        elif counter == 1:\n",
    "            result_1.append(ridge_error_1)\n",
    "            result_1.append(ridge_error_2)\n",
    "            result_1.append(ridge_error_3)\n",
    "        elif counter == 2:\n",
    "            result_2.append(ridge_error_1)\n",
    "            result_2.append(ridge_error_2)\n",
    "            result_2.append(ridge_error_3)\n",
    "        elif counter == 3:\n",
    "            result_3.append(ridge_error_1)\n",
    "            result_3.append(ridge_error_2)\n",
    "            result_3.append(ridge_error_3)\n",
    "        elif counter == 4:\n",
    "            result_4.append(ridge_error_1)\n",
    "            result_4.append(ridge_error_2)\n",
    "            result_4.append(ridge_error_3)\n",
    "        elif counter == 5:\n",
    "            result_5.append(ridge_error_1)\n",
    "            result_5.append(ridge_error_2)\n",
    "            result_5.append(ridge_error_3)\n",
    "        else:\n",
    "            result_6.append(ridge_error_1)\n",
    "            result_6.append(ridge_error_2)\n",
    "            result_6.append(ridge_error_3)\n",
    "            \n",
    "        # update the counter\n",
    "        counter += 1\n",
    "    \n",
    "    for g in s: \n",
    "        if g == 0.2:\n",
    "            average_error = np.average(result_0)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "        elif g == 0.4:\n",
    "            average_error = np.average(result_1)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "        elif g == 0.8:\n",
    "            average_error = np.average(result_2)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "        elif g == 1.0:\n",
    "            average_error = np.average(result_3)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "        elif g == 1.2:\n",
    "            average_error = np.average(result_4)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "        elif g == 1.4:\n",
    "            average_error = np.average(result_5)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "        else:\n",
    "            average_error = np.average(result_6)\n",
    "            print(f\"The average error for {g} is: {average_error}\")\n",
    "            \n",
    "    \n",
    "# PRINT THE STUFF\n",
    "ls_average = least_squares_average()\n",
    "print(f\"The average error for least squares is: {ls_average}\")\n",
    "print()\n",
    "print(\"The average error for ridge regression\")\n",
    "ridge_average()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
